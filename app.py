import streamlit as st
import asyncio
import sys
import traceback
from datetime import datetime
from typing import Optional, AsyncGenerator, Dict, List, Tuple, Union
import json
import time

# Adicionar src ao path para importa√ß√µes
sys.path.append('src')

from dotenv import load_dotenv

from src.core.legal_models import LegalQuery, Priority, ValidationLevel
from src.core.workflow_builder import build_graph
from src.agents.streaming.response_synthesizer import synthesize_response_streaming

# Importar sistema de observabilidade COMPLETO
from src.core.observability import (
    trace_legal_query, 
    trace_crag_execution, 
    trace_hybrid_processing,
    track_crag_retrieval,
    track_data_integration,
    log_detailed_state,
    log_data_flow_checkpoint,
    log_performance_metrics,
    log_state_transition,
    serialize_for_langfuse,
    extract_metadata
)

# Carregar vari√°veis de ambiente
load_dotenv()

# Dicion√°rio de tradu√ß√µes
TRANSLATIONS = {
    "pt": {
        "page_title": "üî• Sistema Jur√≠dico AI Avan√ßado",
        "page_subtitle": "PydanticAI + LangGraph + ChromaDB + LexML + Tavily",
        "page_description": "Sistema de IA jur√≠dica avan√ßado para consultas especializadas ‚ö°",
        "language_selector": "Idioma / Language",
        "legal_consultation": "üí¨ Consulta Jur√≠dica",
        "chat_placeholder": "Digite sua consulta jur√≠dica...",
        "processing": "ü§ñ **Processando sua consulta jur√≠dica...**",
        "processing_complete": "‚úÖ Processamento conclu√≠do!",
        "legal_response": "üìã Resposta Jur√≠dica",
        "disclaimer": "‚ö†Ô∏è Disclaimer:",
        "error_processing": "Erro no processamento:",
        "invalid_response_format": "Formato de resposta inv√°lido",
        "unexpected_response_type": "Tipo de resposta inesperado:",
        "processing_failed": "Falha ao processar consulta",
        "unexpected_error": "Erro inesperado no sistema:",
        "technical_details": "Ver detalhes t√©cnicos",
        "footer_title": "Sistema Jur√≠dico AI Avan√ßado",
        "footer_subtitle": "PydanticAI + LangGraph + ChromaDB",
        "footer_apis": "üèóÔ∏è Todas as APIs: OpenRouter + Groq + Tavily + LexML + Google",
        "footer_disclaimer": "‚öñÔ∏è Para consultas espec√≠ficas, sempre consulte um advogado especializado",
        "disclaimer_text": "Esta resposta foi gerada por sistema de IA integrado e est√° suscet√≠vel a erro. Para qualquer conclus√£o e tomada de descis√£o procure um advogado credenciado e qualificado.",
        "how_it_works": "üß† Como o Sistema Funciona",
        "system_description": "Este √© um sistema de IA jur√≠dica avan√ßado que combina m√∫ltiplas tecnologias para fornecer respostas jur√≠dicas precisas e bem fundamentadas.",
        "step1_title": "1. üìö Coleta de Informa√ß√µes",
        "step1_desc": "O sistema busca informa√ß√µes em m√∫ltiplas fontes: banco de dados vetorial ChromaDB com documentos jur√≠dicos, jurisprud√™ncias do LexML, e informa√ß√µes atualizadas da web via Tavily.",
        "step2_title": "2. üîç An√°lise Inteligente",
        "step2_desc": "Usando LangGraph e PydanticAI, o sistema analisa sua consulta, seleciona os documentos mais relevantes e processa as informa√ß√µes de forma estruturada.",
        "step3_title": "3. ‚öñÔ∏è S√≠ntese Jur√≠dica",
        "step3_desc": "O sistema sintetiza todas as informa√ß√µes coletadas em uma resposta jur√≠dica completa, com an√°lise doutrin√°ria, jurisprudencial e considera√ß√µes pr√°ticas.",
        "technologies_title": "üõ†Ô∏è Tecnologias Utilizadas",
        "tech_langgraph": "**LangGraph**: Orquestra√ß√£o de fluxos de trabalho complexos",
        "tech_pydantic": "**PydanticAI**: Valida√ß√£o e estrutura√ß√£o de dados",
        "tech_chromadb": "**ChromaDB**: Banco de dados vetorial para busca sem√¢ntica",
        "tech_lexml": "**LexML**: Acesso a jurisprud√™ncias e legisla√ß√£o",
        "tech_tavily": "**Tavily**: Busca web para informa√ß√µes atualizadas",
        "tech_openrouter": "**OpenRouter**: Modelos de IA avan√ßados para an√°lise",
        "tech_groq": "**Groq**: Processamento r√°pido de consultas"
    },
    "en": {
        "page_title": "üî• Advanced Legal AI System",
        "page_subtitle": "PydanticAI + LangGraph + ChromaDB + LexML + Tavily",
        "page_description": "Advanced legal AI system for specialized consultations ‚ö°",
        "language_selector": "Language / Idioma",
        "legal_consultation": "üí¨ Legal Consultation",
        "chat_placeholder": "Enter your legal query...",
        "processing": "ü§ñ **Processing your legal query...**",
        "processing_complete": "‚úÖ Processing completed!",
        "legal_response": "üìã Legal Response",
        "disclaimer": "‚ö†Ô∏è Disclaimer:",
        "error_processing": "Processing error:",
        "invalid_response_format": "Invalid response format",
        "unexpected_response_type": "Unexpected response type:",
        "processing_failed": "Failed to process query",
        "unexpected_error": "Unexpected system error:",
        "technical_details": "View technical details",
        "footer_title": "Advanced Legal AI System",
        "footer_subtitle": "PydanticAI + LangGraph + ChromaDB",
        "footer_apis": "üèóÔ∏è All APIs: OpenRouter + Groq + Tavily + LexML + Google",
        "footer_disclaimer": "‚öñÔ∏è For specific queries, always consult a specialized lawyer",
        "disclaimer_text": "This response was generated by an integrated AI system and is subject to error. For any conclusion and decision making, seek a licensed and qualified lawyer.",
        "how_it_works": "üß† How the System Works",
        "system_description": "This is an advanced legal AI system that combines multiple technologies to provide accurate and well-founded legal responses.",
        "step1_title": "1. üìö Information Collection",
        "step1_desc": "The system searches information from multiple sources: ChromaDB vector database with legal documents, LexML jurisprudence, and updated web information via Tavily.",
        "step2_title": "2. üîç Intelligent Analysis",
        "step2_desc": "Using LangGraph and PydanticAI, the system analyzes your query, selects the most relevant documents and processes information in a structured way.",
        "step3_title": "3. ‚öñÔ∏è Legal Synthesis",
        "step3_desc": "The system synthesizes all collected information into a complete legal response, with doctrinal analysis, jurisprudence and practical considerations.",
        "technologies_title": "üõ†Ô∏è Technologies Used",
        "tech_langgraph": "**LangGraph**: Orchestration of complex workflows",
        "tech_pydantic": "**PydanticAI**: Data validation and structuring",
        "tech_chromadb": "**ChromaDB**: Vector database for semantic search",
        "tech_lexml": "**LexML**: Access to jurisprudence and legislation",
        "tech_tavily": "**Tavily**: Web search for updated information",
        "tech_openrouter": "**OpenRouter**: Advanced AI models for analysis",
        "tech_groq": "**Groq**: Fast query processing"
    }
}

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="üî• Legal AI System - Sistema Jur√≠dico AI",
    page_icon="‚öñÔ∏è",
    layout="wide"
)

# Seletor de idioma no topo
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    language = st.selectbox(
        "üåê Language / Idioma",
        options=["pt", "en"],
        format_func=lambda x: "üáßüá∑ Portugu√™s" if x == "pt" else "üá∫üá∏ English",
        index=0
    )

# Obter tradu√ß√µes para o idioma selecionado
t = TRANSLATIONS[language]

# CSS customizado
st.markdown("""
<style>
.main-header {
    background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
    padding: 2rem;
    border-radius: 10px;
    color: white;
    margin-bottom: 2rem;
    text-align: center;
}

.error-box {
    background: #ffebee;
    padding: 1rem;
    border-radius: 8px;
    border-left: 4px solid #f44336;
    margin: 1rem 0;
}

.success-box {
    background: #f1f8e9;
    padding: 1rem;
    border-radius: 8px;
    border-left: 4px solid #4CAF50;
    margin: 1rem 0;
}


</style>
""", unsafe_allow_html=True)

# Header
st.markdown(f"""
<div class="main-header">
    <h1>{t["page_title"]}</h1>
    <h3>{t["page_subtitle"]}</h3>
    <p>{t["page_description"]}</p>
</div>
""", unsafe_allow_html=True)

# Se√ß√£o opcional "Como Funciona" com expander
with st.expander(f"üß† {t['how_it_works']}", expanded=False):
    
    # Descri√ß√£o principal
    st.markdown(f"<p style='font-size: 1.1em; margin-bottom: 1rem; text-align: center; color: #333333; line-height: 1.5;'>{t['system_description']}</p>", unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Passos do sistema usando containers nativos do Streamlit
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown(f"""
        <div style="background: white; padding: 1.5rem; border-radius: 8px; margin: 0.5rem 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-left: 4px solid #4CAF50;">
            <h4 style="color: #2a5298; margin-top: 0;">{t["step1_title"]}</h4>
            <p style="margin-bottom: 0; color: #333333; font-size: 14px; line-height: 1.4;">{t["step1_desc"]}</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="background: white; padding: 1.5rem; border-radius: 8px; margin: 0.5rem 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-left: 4px solid #2196F3;">
            <h4 style="color: #2a5298; margin-top: 0;">{t["step2_title"]}</h4>
            <p style="margin-bottom: 0; color: #333333; font-size: 14px; line-height: 1.4;">{t["step2_desc"]}</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="background: white; padding: 1.5rem; border-radius: 8px; margin: 0.5rem 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-left: 4px solid #FF9800;">
            <h4 style="color: #2a5298; margin-top: 0;">{t["step3_title"]}</h4>
            <p style="margin-bottom: 0; color: #333333; font-size: 14px; line-height: 1.4;">{t["step3_desc"]}</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Tecnologias
    st.markdown(f"<h3 style='text-align: center; color: #2a5298; margin-top: 1rem;'>{t['technologies_title']}</h3>", unsafe_allow_html=True)
    
    # Grid de tecnologias usando colunas do Streamlit
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"""
        <div style="background: white; padding: 1rem; border-radius: 8px; margin: 0.5rem 0; border-left: 4px solid #2a5298; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
            <p style="margin: 0; font-weight: bold; color: #2a5298; font-size: 14px;">{t["tech_langgraph"]}</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div style="background: white; padding: 1rem; border-radius: 8px; margin: 0.5rem 0; border-left: 4px solid #2a5298; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
            <p style="margin: 0; font-weight: bold; color: #2a5298; font-size: 14px;">{t["tech_chromadb"]}</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div style="background: white; padding: 1rem; border-radius: 8px; margin: 0.5rem 0; border-left: 4px solid #2a5298; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
            <p style="margin: 0; font-weight: bold; color: #2a5298; font-size: 14px;">{t["tech_tavily"]}</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div style="background: white; padding: 1rem; border-radius: 8px; margin: 0.5rem 0; border-left: 4px solid #2a5298; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
            <p style="margin: 0; font-weight: bold; color: #2a5298; font-size: 14px;">{t["tech_groq"]}</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="background: white; padding: 1rem; border-radius: 8px; margin: 0.5rem 0; border-left: 4px solid #2a5298; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
            <p style="margin: 0; font-weight: bold; color: #2a5298; font-size: 14px;">{t["tech_pydantic"]}</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div style="background: white; padding: 1rem; border-radius: 8px; margin: 0.5rem 0; border-left: 4px solid #2a5298; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
            <p style="margin: 0; font-weight: bold; color: #2a5298; font-size: 14px;">{t["tech_lexml"]}</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div style="background: white; padding: 1rem; border-radius: 8px; margin: 0.5rem 0; border-left: 4px solid #2a5298; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
            <p style="margin: 0; font-weight: bold; color: #2a5298; font-size: 14px;">{t["tech_openrouter"]}</p>
        </div>
        """, unsafe_allow_html=True)

# Fun√ß√£o para importar e carregar o sistema
@st.cache_resource
def load_system():
    """Carrega o sistema uma vez e mant√©m em cache"""
    try:
        from src.core.legal_models import LegalQuery, Priority, ValidationLevel
        from src.core.workflow_builder import build_graph
        
        # Construir o grafo
        app = build_graph()
        
        return {
            "app": app,
            "LegalQuery": LegalQuery,
            "Priority": Priority,
            "ValidationLevel": ValidationLevel,
            "status": "success",
            "message": "Sistema carregado com sucesso!"
        }
    except Exception as e:
        return {
            "app": None,
            "status": "error",
            "message": f"Erro ao carregar sistema: {str(e)}",
            "error": traceback.format_exc()
        }

# Carregar sistema
system = load_system()

# Verificar status do sistema (sem mostrar detalhes)
if system["status"] != "success":
    st.markdown(f"""
    <div class="error-box">
        <h4>‚ùå System Error / Erro no Sistema</h4>
        <p>{system["message"]}</p>
        <details>
            <summary>Ver detalhes do erro / View error details</summary>
            <pre>{system.get("error", "Sem detalhes")}</pre>
        </details>
    </div>
    """, unsafe_allow_html=True)
    st.stop()

# Interface principal
st.markdown(f"## {t['legal_consultation']}")

# Fun√ß√£o para processar query
async def process_legal_query(query_text: str, priority, validation_level, use_hybrid: bool):
    """
    Processa consulta jur√≠dica com observabilidade COMPLETA.
    Rastreia cada etapa e transfer√™ncia de dados com Langfuse.
    """
    
    start_time = time.time()
    language = "pt"  # Portugu√™s brasileiro
    
    try:
        # Criar objeto LegalQuery
        query = LegalQuery(
            id=f"query_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}",
            text=query_text,
            user_id="streamlit_user",
            priority=priority,
            validation_level=validation_level,
            language=language
        )
        
        # INICIAR RASTREAMENTO LANGFUSE COMPLETO
        with trace_legal_query(query.id, query_text) as trace:
            
            log_data_flow_checkpoint("query_creation", {
                "query_id": query.id,
                "query_text": query_text[:100],
                "priority": str(priority),
                "validation_level": str(validation_level),
                "use_hybrid": use_hybrid
            })
            
            # Carregar sistema uma vez
            system = load_system()
            
            if use_hybrid:
                yield ("progress", "üöÄ Sistema h√≠brido integrado com observabilidade..." if language == "pt" else "üöÄ Integrated hybrid system with observability...")
                
                # ===================================================================
                # ETAPA 1: COLETA DE DADOS CRAG (COM RASTREAMENTO COMPLETO)
                # ===================================================================
                
                with trace_crag_execution(query_text) as crag_span:
                    yield ("progress", "üìö Coletando dados do CRAG (rastreado)..." if language == "pt" else "üìö Collecting CRAG data (tracked)...")
                    
                    # Estado inicial para o grafo CRAG (apenas para busca de dados)
                    initial_crag_state = {
                        "query": query,
                        "current_query": query.text,
                        "retrieved_docs": [],
                        "tavily_results": None,
                        "lexml_results": None,
                        "needs_jurisprudencia": True,
                        "grade": None,
                        "transformed_query": None,
                        "should_synthesize": True,   # CORRIGIDO: Permite transfer√™ncia de dados para h√≠brido
                        "history": [],
                        "final_response": None,
                        "error": None,
                        "next_node": None
                    }
                    
                    # LOG DETALHADO: Estado inicial
                    log_detailed_state(initial_crag_state, "crag_initial_state")
                    
                    # Configura√ß√£o do grafo
                    config = {
                        "recursion_limit": 50,
                        "configurable": {
                            "thread_id": f"crag-{query.id}"
                        }
                    }
                    
                    # Executar CRAG apenas para coleta de dados (parar antes da s√≠ntese) - RASTREADO
                    crag_data = {}
                    event_count = 0
                    final_crag_state = None
                    
                    crag_start_time = time.time()
                    
                    async for event in system["app"].astream(initial_crag_state, config=config):
                        event_count += 1
                        
                        for node_name, state_update in event.items():
                            yield ("progress", f"CRAG: {node_name.replace('_', ' ').title()}")
                            
                            # LOG DETALHADO: Cada n√≥ do CRAG
                            if state_update:
                                detailed_state = log_detailed_state(state_update, f"crag_node_{node_name}")
                                
                                # CHECKPOINT: Estado ap√≥s cada n√≥
                                log_data_flow_checkpoint(f"crag_after_{node_name}", detailed_state)
                                
                                # Log transi√ß√£o de estado
                                log_state_transition(
                                    from_state=final_crag_state.get("next_node", "unknown") if final_crag_state else "initial",
                                    to_state=node_name,
                                    reason=f"CRAG workflow step: {node_name}"
                                )
                            
                            final_crag_state = state_update
                            
                            # CORRE√á√ÉO: Acumular dados cr√≠ticos preservando coletas anteriores
                            if state_update:
                                # Preservar dados coletados nos n√≥s anteriores
                                for key in ["retrieved_docs", "tavily_results", "lexml_results"]:
                                    if state_update.get(key) and key not in crag_data:
                                        crag_data[key] = state_update[key]
                                    elif state_update.get(key) and crag_data.get(key):
                                        # Combinar dados se ambos existem
                                        if isinstance(state_update[key], list) and isinstance(crag_data[key], list):
                                            crag_data[key].extend(state_update[key])
                                        else:
                                            crag_data[key] = state_update[key]
                                
                                # Atualizar outros campos normalmente
                                for key, value in state_update.items():
                                    if key not in ["retrieved_docs", "tavily_results", "lexml_results"]:
                                        crag_data[key] = value
                            
                            # N√ÉO parar - deixar CRAG completar para preservar dados
                            # CORRE√á√ÉO: Remover quebra prematura que perde dados
                            pass
                        
                        # Limitar eventos para evitar loops
                        if event_count >= 15:
                            break
                    
                    crag_duration = time.time() - crag_start_time
                    log_performance_metrics("crag_data_collection", crag_duration * 1000, events_processed=event_count)
                    
                    # CORRE√á√ÉO: Usar dados acumulados em vez do estado final que pode estar limpo
                    if final_crag_state:
                        # Manter dados j√° coletados se final_state estiver vazio
                        for key in ["retrieved_docs", "tavily_results", "lexml_results"]:
                            if final_crag_state.get(key) and not crag_data.get(key):
                                crag_data[key] = final_crag_state[key]
                            elif not final_crag_state.get(key) and crag_data.get(key):
                                # Preservar dados acumulados se final_state perdeu os dados
                                pass
                        
                        # LOG DETALHADO: Estado final do CRAG
                        final_state_summary = log_detailed_state(crag_data, "crag_final_state_corrected")
                        log_data_flow_checkpoint("crag_completion", final_state_summary)
                    
                    # ===================================================================
                    # EXTRA√á√ÉO E PROCESSAMENTO DE DADOS CRAG (RASTREAMENTO DETALHADO)
                    # ===================================================================
                    
                    # Debug: verificar dados coletados do CRAG - RASTREAMENTO COMPLETO
                    retrieved_docs = crag_data.get("retrieved_docs", [])
                    tavily_results = crag_data.get("tavily_results", [])
                    lexml_results = crag_data.get("lexml_results", [])
                    
                    # LOG CR√çTICO: Dados brutos extra√≠dos
                    raw_data_summary = {
                        "retrieved_docs_type": type(retrieved_docs).__name__,
                        "retrieved_docs_count": len(retrieved_docs) if retrieved_docs else 0,
                        "tavily_results_type": type(tavily_results).__name__,
                        "tavily_results_count": len(tavily_results) if isinstance(tavily_results, list) else (1 if tavily_results else 0),
                        "lexml_results_type": type(lexml_results).__name__,
                        "lexml_results_count": len(lexml_results) if isinstance(lexml_results, list) else (1 if lexml_results else 0)
                    }
                    
                    log_data_flow_checkpoint("raw_data_extraction", raw_data_summary)
                    
                    # RASTREAMENTO: Documentos CRAG
                    if retrieved_docs:
                        track_crag_retrieval(query_text, retrieved_docs)
                    
                    # CORRE√á√ÉO CR√çTICA: Processar estrutura real dos documentos - RASTREADO
                    processed_docs = []
                    if retrieved_docs and isinstance(retrieved_docs, list):
                        print(f"üîç DEBUG: Processando {len(retrieved_docs)} documentos CRAG...")
                        for i, doc in enumerate(retrieved_docs):
                            print(f"  üìÑ Doc {i+1}: Tipo = {type(doc).__name__}")
                            
                            doc_metadata = extract_metadata(doc)
                            
                            # ESTRAT√âGIAS OTIMIZADAS DE EXTRA√á√ÉO (hier√°rquica)
                            content = None
                            extraction_method = ""
                            
                            # Estrat√©gia 1: DocumentSnippet.text (Sistema personalizado - OTIMIZADO)
                            if hasattr(doc, 'text') and doc.text:
                                content = doc.text
                                extraction_method = "document_snippet_text"
                                print(f"    ‚úÖ Extra√≠do via DocumentSnippet.text: {len(content)} chars")
                            
                            # Estrat√©gia 2: Atributo page_content (LangChain padr√£o)
                            elif hasattr(doc, 'page_content') and doc.page_content:
                                content = doc.page_content
                                extraction_method = "langchain_page_content"
                                print(f"    ‚úÖ Extra√≠do via page_content: {len(content)} chars")
                            
                            # Estrat√©gia 3: Dict com 'content'
                            elif isinstance(doc, dict) and 'content' in doc:
                                content = doc['content']
                                extraction_method = "dict_content"
                                print(f"    ‚úÖ Extra√≠do via dict['content']: {len(content)} chars")
                            
                            # Estrat√©gia 4: Dict com 'page_content'
                            elif isinstance(doc, dict) and 'page_content' in doc:
                                content = doc['page_content']
                                extraction_method = "dict_page_content"
                                print(f"    ‚úÖ Extra√≠do via dict['page_content']: {len(content)} chars")
                            
                            # Estrat√©gia 5: String direta
                            elif isinstance(doc, str):
                                content = doc
                                extraction_method = "direct_string"
                                print(f"    ‚úÖ Extra√≠do via string direta: {len(content)} chars")
                            
                            # Estrat√©gia 6: Fallback - Serializar objeto completo
                            else:
                                content = str(doc)
                                extraction_method = "fallback_str"
                                print(f"    ‚ö†Ô∏è Fallback para str(doc): {len(content)} chars")
                            
                            if content and len(content.strip()) > 10:
                                processed_docs.append({
                                    'content': content,
                                    'metadata': getattr(doc, 'metadata', {}) if hasattr(doc, 'metadata') else {},
                                    'source': 'crag_vectordb',
                                    'index': i,
                                    'original_type': type(doc).__name__,
                                    'extraction_method': extraction_method,  # OTIMIZA√á√ÉO: Track m√©todo usado
                                    'content_preview': content[:100] + "..." if len(content) > 100 else content,
                                    'content_length': len(content)  # OTIMIZA√á√ÉO: Track tamanho
                                })
                                print(f"    ‚úÖ Doc {i+1} processado e adicionado via {extraction_method}!")
                            else:
                                print(f"    ‚ùå Doc {i+1} descartado - conte√∫do insuficiente ({len(content.strip()) if content else 0} chars)")
                        
                        # M√âTRICAS DE OTIMIZA√á√ÉO: Contabilizar m√©todos de extra√ß√£o
                        extraction_stats = {}
                        total_content_length = 0
                        for doc in processed_docs:
                            method = doc.get('extraction_method', 'unknown')
                            extraction_stats[method] = extraction_stats.get(method, 0) + 1
                            total_content_length += doc.get('content_length', 0)
                        
                        print(f"üìä RESULTADO: {len(processed_docs)}/{len(retrieved_docs)} docs CRAG processados com sucesso")
                        print(f"üìà M√âTRICAS DE EXTRA√á√ÉO:")
                        for method, count in extraction_stats.items():
                            emoji = "üöÄ" if method == "document_snippet_text" else "‚ö†Ô∏è" if method == "fallback_str" else "‚úÖ"
                            print(f"    {emoji} {method}: {count} docs")
                        print(f"üìè CONTE√öDO TOTAL: {total_content_length:,} chars ({total_content_length/len(processed_docs):.0f} chars/doc)")
                        
                        # Log das m√©tricas para observabilidade
                        log_data_flow_checkpoint("extraction_optimization_metrics", {
                            "extraction_methods": extraction_stats,
                            "total_docs": len(processed_docs),
                            "total_content_length": total_content_length,
                            "avg_content_per_doc": total_content_length / len(processed_docs) if processed_docs else 0,
                            "optimization_success": extraction_stats.get("document_snippet_text", 0) > extraction_stats.get("fallback_str", 0)
                        })
                    
                    # CORRE√á√ÉO CR√çTICA: Processar resultados Tavily - RASTREADO
                    processed_tavily = []
                    if tavily_results:
                        if isinstance(tavily_results, list):
                            for i, result in enumerate(tavily_results):
                                processed_tavily.append({
                                    **serialize_for_langfuse(result),
                                    'source': 'tavily_web',
                                    'index': i
                                })
                        elif tavily_results is not None:
                            processed_tavily = [{
                                **serialize_for_langfuse(tavily_results),
                                'source': 'tavily_web',
                                'index': 0
                            }]
                    
                    # CORRE√á√ÉO CR√çTICA: Processar resultados LexML - RASTREADO
                    processed_lexml = []
                    if lexml_results:
                        if isinstance(lexml_results, list):
                            for i, result in enumerate(lexml_results):
                                processed_lexml.append({
                                    **serialize_for_langfuse(result),
                                    'source': 'lexml_jurisprudence',
                                    'index': i
                                })
                        elif lexml_results is not None:
                            processed_lexml = [{
                                **serialize_for_langfuse(lexml_results),
                                'source': 'lexml_jurisprudence', 
                                'index': 0
                            }]
                    
                    # LOG CR√çTICO: Dados processados
                    processed_data_summary = {
                        "processed_docs_count": len(processed_docs),
                        "processed_tavily_count": len(processed_tavily),
                        "processed_lexml_count": len(processed_lexml),
                        "total_processed_sources": len(processed_docs) + len(processed_tavily) + len(processed_lexml)
                    }
                    
                    log_data_flow_checkpoint("processed_data_summary", processed_data_summary)
                    
                    # RASTREAMENTO: Integra√ß√£o de dados
                    if processed_docs or processed_tavily or processed_lexml:
                        integration_data = track_data_integration(processed_docs, processed_lexml, processed_tavily)
                        crag_span.update(output=integration_data)
                    
                    yield ("progress", f"üìä CRAG PROCESSADO E RASTREADO: {len(processed_docs)} docs, {len(processed_tavily)} tavily, {len(processed_lexml)} lexml")
                
                # ===================================================================
                # ETAPA 2: PROCESSAMENTO H√çBRIDO INTEGRADO (COM RASTREAMENTO)
                # ===================================================================
                
                hybrid_data_summary = {
                    "total_sources": len(processed_docs) + len(processed_tavily) + len(processed_lexml),
                    "crag_docs": len(processed_docs),
                    "tavily_results": len(processed_tavily),
                    "lexml_results": len(processed_lexml)
                }
                
                with trace_hybrid_processing(query_text, hybrid_data_summary) as hybrid_span:
                    yield ("progress", "üîß Processamento h√≠brido integrado e rastreado..." if language == "pt" else "üîß Integrated and tracked hybrid processing...")
                    
                    # LOG CR√çTICO: Dados sendo passados para o sistema h√≠brido
                    log_data_flow_checkpoint("hybrid_input_data", {
                        "processed_docs_sample": processed_docs[:2] if processed_docs else [],
                        "processed_tavily_sample": processed_tavily[:1] if processed_tavily else [],
                        "processed_lexml_sample": processed_lexml[:1] if processed_lexml else [],
                        "total_sources_passed": hybrid_data_summary["total_sources"]
                    })
                    
                    # Importar fun√ß√£o h√≠brida espec√≠fica que aceita dados externos
                    from src.agents.streaming.hybrid_legal_processor import process_legal_query_hybrid_with_crag_data
                    
                    hybrid_start_time = time.time()
                    final_result = None
                    
                    async for step_type, content in process_legal_query_hybrid_with_crag_data(
                        query, 
                        crag_retrieved_docs=processed_docs,  # Usar dados processados e rastreados
                        crag_tavily_results=processed_tavily,  # Usar dados processados e rastreados
                        crag_lexml_results=processed_lexml  # Usar dados processados e rastreados
                    ):
                        if step_type == "progress":
                            yield ("progress", content)
                        elif step_type == "final":
                            final_result = content
                            break
                        elif step_type == "error":
                            yield ("error", content)
                            return
                    
                    hybrid_duration = time.time() - hybrid_start_time
                    log_performance_metrics("hybrid_processing", hybrid_duration * 1000, 
                                           sources_used=hybrid_data_summary["total_sources"])
                    
                    if final_result:
                        # LOG FINAL: Resultado h√≠brido
                        final_result_metadata = extract_metadata(final_result)
                        log_data_flow_checkpoint("hybrid_final_result", final_result_metadata)
                        
                        hybrid_span.update(output={
                            "result_metadata": final_result_metadata,
                            "processing_successful": True
                        })
                        
                        yield ("final", final_result)
                    else:
                        error_msg = "Sistema h√≠brido integrado n√£o retornou resultado" if language == "pt" else "Integrated hybrid system did not return result"
                        log_data_flow_checkpoint("hybrid_error", {"error": error_msg})
                        yield ("error", error_msg)
            
            else:
                # Sistema original CRAG sem h√≠brido - TAMB√âM RASTREADO
                yield ("progress", "ü§ñ Processando com sistema CRAG padr√£o rastreado..." if language == "pt" else "ü§ñ Processing with tracked standard CRAG system...")
                
                # Estado inicial para o grafo
                initial_state = {
                    "query": query,
                    "current_query": query.text,
                    "retrieved_docs": [],
                    "tavily_results": None,
                    "lexml_results": None,
                    "needs_jurisprudencia": True,
                    "grade": None,
                    "transformed_query": None,
                    "should_synthesize": True,   # CORRIGIDO: Permite s√≠ntese normal
                    "history": [],
                    "final_response": None,
                    "error": None,
                    "next_node": None
                }
                
                # Configura√ß√£o do grafo
                config = {
                    "recursion_limit": 50,
                    "configurable": {
                        "thread_id": f"streamlit-{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    }
                }
                
                # Executar o grafo
                final_state = None
                event_count = 0
                
                async for event in system["app"].astream(initial_state, config=config):
                    event_count += 1
                    
                    for node_name, state_update in event.items():
                        yield ("progress", f"üîÑ {node_name.replace('_', ' ').title()}")
                        final_state = state_update
                    
                    if event_count >= 20:
                        break
                
                if final_state and final_state.get("final_response"):
                    yield ("final", final_state["final_response"])
                else:
                    yield ("error", "Sistema CRAG n√£o retornou resposta final" if language == "pt" else "CRAG system did not return final response")
            
            total_duration = time.time() - start_time
            log_performance_metrics("complete_legal_query", total_duration * 1000,
                                   query_length=len(query_text),
                                   use_hybrid=use_hybrid)
        
    except Exception as e:
        error_msg = f"Erro ao processar consulta: {str(e)}" if language == "pt" else f"Error processing query: {str(e)}"
        
        # LOG ERRO COMPLETO
        log_data_flow_checkpoint("fatal_error", {
            "error_message": str(e),
            "error_type": type(e).__name__,
            "query_text": query_text[:100]
        })
        
        yield ("error", error_msg)

# Interface de chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar mensagens anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usu√°rio
if prompt := st.chat_input(t["chat_placeholder"]):
    
    # Adicionar mensagem do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Processar resposta
    with st.chat_message("assistant"):
        
        # Container para resposta
        response_container = st.container()
        
        with response_container:
            st.markdown(t["processing"])
            
            # Elementos de interface
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                final_result = None
                
                # Fun√ß√£o para executar processamento
                def run_processing():
                    async def process_coroutine():
                        progress_count = 0
                        async for step_type, content in process_legal_query(
                            prompt, 
                            system["Priority"].MEDIUM,  # Prioridade padr√£o
                            system["ValidationLevel"].MODERATE,  # Valida√ß√£o padr√£o
                            True  # Usar h√≠brido
                        ):
                            
                            if step_type == "progress":
                                progress_count += 1
                                progress = min(progress_count / 10.0, 0.9)
                                progress_bar.progress(progress)
                                status_text.text(content)
                            
                            elif step_type == "final":
                                return content
                            
                            elif step_type == "error":
                                st.error(f"{t['error_processing']} {content}")
                                return None
                        
                        return None
                    
                    return asyncio.run(process_coroutine())
                
                # Executar processamento
                final_result = run_processing()
                
                # Limpar progress quando terminar
                progress_bar.progress(1.0)
                status_text.text(t["processing_complete"])
                
                if final_result:
                    # Limpar elementos de progresso
                    time.sleep(1)
                    progress_bar.empty()
                    status_text.empty()
                    
                    # Processar resultado
                    if isinstance(final_result, dict):
                        if "overall_summary" in final_result:
                            summary = final_result["overall_summary"]
                            disclaimer = final_result.get("disclaimer", "")
                            
                            # Exibir resposta final formatada
                            st.markdown(f"### {t['legal_response']}")
                            st.markdown(summary)
                            
                            if disclaimer:
                                st.markdown("---")
                                st.markdown(f"**{t['disclaimer']}**")
                                st.markdown(disclaimer)
                            
                            # Adicionar √† sess√£o
                            full_response = f"### {t['legal_response']}\n\n{summary}"
                            if disclaimer:
                                full_response += f"\n\n**{t['disclaimer']}** {disclaimer}"
                            
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": full_response
                            })
                            
                        else:
                            error_msg = t["invalid_response_format"]
                            st.error(error_msg)
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": f"‚ùå {error_msg}"
                            })
                    
                    else:
                        error_msg = f"{t['unexpected_response_type']} {type(final_result)}"
                        st.error(error_msg)
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": f"‚ùå {error_msg}"
                        })
                
                else:
                    error_msg = t["processing_failed"]
                    st.error(error_msg)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"‚ùå {error_msg}"
                    })
                    
            except Exception as e:
                # Limpar progress em caso de erro
                progress_bar.empty()
                status_text.empty()
                
                error_msg = f"{t['unexpected_error']} {str(e)}"
                st.error(error_msg)
                
                # Mostrar traceback em expander
                with st.expander(t["technical_details"]):
                    st.code(traceback.format_exc())
                
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"‚ùå {error_msg}"
                })

# Footer
st.markdown("---")
st.markdown(f"""
<div style="text-align: center; color: #666; margin-top: 2rem;">
    <p><strong>{t["footer_title"]}</strong> | {t["footer_subtitle"]}</p>
    <p>{t["footer_apis"]}</p>
    <p>{t["footer_disclaimer"]}</p>
</div>
""", unsafe_allow_html=True) 